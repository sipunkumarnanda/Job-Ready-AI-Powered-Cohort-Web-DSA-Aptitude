
## **üìå Real-Time AI Chatbot using Socket.IO and Google Gemini**

---

### **1. File Structure & Code**

---

#### **Backend Folder Structure**

```
Backend/
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ service/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ai.service.js
‚îÇ   ‚îî‚îÄ‚îÄ app.js         (Not shown, likely Express app setup)
‚îÇ
‚îú‚îÄ‚îÄ server.js
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ package.json
```

---

#### **`/src/service/ai.service.js`**

```javascript
import { GoogleGenAI } from "@google/genai";
import dotenv from 'dotenv';
dotenv.config();

const ai = new GoogleGenAI({
    apiKey : process.env.GEMINI_API_KEY
});

async function generateResponse(chatHistory) {
    const response = await ai.models.generateContent({
        model : "gemini-2.0-flash",
        contents : chatHistory
    });

    return response.text;
}

export default generateResponse;
```

---

#### **`server.js`**

```javascript
import dotenv from 'dotenv';
import app from "./src/app.js";
import { createServer } from "http";
import { Server } from "socket.io";
import generateResponse from './src/service/ai.service.js';

dotenv.config();

const httpServer = createServer(app);
const io = new Server(httpServer, {
    cors : {
        origin : 'http://localhost:5173',
    }
});

const chatHistory = [];

io.on("connection", (socket) => {
   console.log("A user connected"); 

   socket.on("disconnect", () => {
       console.log("A user disconnected");
   });

   // Listen for normal message
   socket.on("message", async (data) => {
       console.log(data);
   });

   // Listen for AI message
   socket.on("ai-message", async (data) => {
       // Add user's message to chat history
       chatHistory.push({
           role : "user",
           parts : [{ text : data }]
       });
       
       // Generate AI response
       const response = await generateResponse(chatHistory);

       // Add AI response to chat history
       chatHistory.push({
           role : "model",
           parts : [{ text : response }]
       });

       // Send AI response back to this client
       socket.emit("ai-message-response", response);
   });
});

httpServer.listen(3000, () => {
    console.log("Server is running on port 3000");
});
```

---

#### **Frontend Folder Structure**

```
Frontend/
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ App.jsx
‚îÇ   ‚îî‚îÄ‚îÄ App.css
‚îú‚îÄ‚îÄ package.json
```

---

#### **`/src/App.jsx`**

```javascript
import React, { useState, useEffect, useRef } from "react";
import { io } from "socket.io-client";
import "./App.css";

export default function App() {
  const [socket, setSocket] = useState(null);
  const [messages, setMessages] = useState([
    {
      id: Date.now() + Math.random(),
      text: "Hello! How can I assist you today?",
      sender: "bot",
      timestamp: new Date().toISOString(),
    },
  ]);

  const [input, setInput] = useState("");
  const messagesEndRef = useRef(null);

  // Auto-scroll to the latest message
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" });
  }, [messages]);

  // Send message to backend
  const handleSendMessage = () => {
    if (!input.trim()) return;

    const newMessage = {
      id: Date.now(),
      text: input.trim(),
      sender: "user",
      timestamp: new Date().toISOString(),
    };

    setMessages((prev) => [...prev, newMessage]);
    socket.emit("ai-message", input.trim());
    setInput("");
  };

  // Receive incoming message from backend
  const incomingMessage = (text) => {
    const incomingMsg = {
      id: Date.now() + Math.random(),
      text,
      sender: "bot",
      timestamp: new Date().toISOString(),
    };
    setMessages((prev) => [...prev, incomingMsg]);
  };

  // Enter key handling
  const handleKeyPress = (e) => {
    if (e.key === "Enter" && !e.shiftKey) {
      e.preventDefault();
      handleSendMessage();
    }
  };

  // Initialize socket connection
  useEffect(() => {
    let socketInstance = io("http://localhost:3000");
    setSocket(socketInstance);

    socketInstance.on("ai-message-response", (response) => {
      incomingMessage(response);
    });
  }, []);

  return (
    <div className="chat-container">
      <div className="chat-header">Chat Interface</div>

      <div className="chat-messages">
        {messages.length === 0 && (
          <div className="no-messages">No messages yet. Start chatting!</div>
        )}

        {messages.map((msg) => (
          <div
            key={msg.id}
            className={`chat-message ${
              msg.sender === "user" ? "right" : "left"
            }`}
          >
            <div className="message-text">{msg.text}</div>
            <div className="message-time">
              {new Date(msg.timestamp).toLocaleTimeString([], {
                hour: "2-digit",
                minute: "2-digit",
              })}
            </div>
          </div>
        ))}

        <div ref={messagesEndRef} />
      </div>

      <div className="chat-input-container">
        <textarea
          rows="1"
          className="chat-input"
          value={input}
          onChange={(e) => setInput(e.target.value)}
          onKeyDown={handleKeyPress}
          placeholder="Type a message..."
        />
        <button onClick={handleSendMessage} disabled={!input.trim()}>
          Send
        </button>
      </div>
    </div>
  );
}
```

---

### **2. Detailed Explanation**

---

#### **A. Backend (Node.js + Express + Socket.IO + Google Gemini)**

1. **`ai.service.js`**

   * Imports Google Gemini SDK.
   * Loads `.env` file for API key.
   * `generateResponse(chatHistory)` takes an array of past messages, sends it to Gemini, and returns the AI‚Äôs generated text.

2. **`server.js`**

   * Creates HTTP server from Express app.
   * Initializes Socket.IO for real-time communication.
   * `chatHistory` keeps a running log of conversation (both user and AI messages).
   * When the frontend emits `"ai-message"`, the backend:

     1. Adds the user message to history.
     2. Calls `generateResponse()` to get AI output.
     3. Adds AI response to history.
     4. Emits `"ai-message-response"` event back to the client.

---

#### **B. Frontend (React + Socket.IO Client)**

1. **State Variables**

   * `messages` ‚Üí stores chat messages.
   * `socket` ‚Üí stores active socket instance.
   * `input` ‚Üí stores user‚Äôs text input.

2. **Flow**

   * **Send Message:**

     * User types message ‚Üí Press Enter or click Send ‚Üí Message added to state ‚Üí Emit `"ai-message"` to backend.
   * **Receive Message:**

     * Backend processes request ‚Üí Sends `"ai-message-response"` event ‚Üí `incomingMessage()` adds it to messages.

3. **Auto-Scroll:**

   * `useRef` + `useEffect` ensures chat view scrolls to the latest message.

4. **Socket Initialization:**

   * Done in `useEffect([])` ‚Üí runs only once when component mounts.

---

#### **C. Real-Time Communication Concept**

* **Emit:** Client ‚Üí Server or Server ‚Üí Client.
* **On (Listener):** Waits for the event and executes code when triggered.
* In your case:

  * Client **emits** `"ai-message"`.
  * Server **listens** for `"ai-message"`, processes AI logic, and **emits** `"ai-message-response"`.
  * Client **listens** for `"ai-message-response"` and updates UI.

---
---
---




## üîç Real-Time AI Chatbot ‚Äî Deep Code Walkthrough (Back-end & Front-end)

Below is a **file-by-file, line-by-line style** explanation of what each part does, why it exists, what data flows through it, and what to watch out for / improve.

---

# üß† Backend

## 1) `src/service/ai.service.js`

### Imports & setup

```js
import { GoogleGenAI } from "@google/genai";
import dotenv from 'dotenv'
dotenv.config()
```

* **`@google/genai`**: SDK wrapper to call Google‚Äôs Gemini models.
* **`dotenv`**: Loads environment variables from `.env` into `process.env`.
* **`dotenv.config()`**: Must be called before you read `process.env.*` so your API key is available.

```js
const ai = new GoogleGenAI({
    apiKey : process.env.GEMINI_API_KEY
});
```

* Creates a **client instance** for the Gemini API using a **secret API key** from `.env`.
* Keep `.env` out of version control.

### Core function

```js
async function  generateResponse(chatHistory) {
    const response = await ai.models.generateContent({
        model : "gemini-2.0-flash",
        contents : chatHistory
    })

    return response.text
}
```

* **`chatHistory`**: An array representing the conversation so far.

  * Each item has a **role** (`"user"` or `"model"`) and **parts** (text chunks).
  * You‚Äôre **prompting with context** so the model replies coherently.
* **`ai.models.generateContent({...})`**: Sends the request to Gemini with:

  * `model`: which model to use (fast ‚Äúflash‚Äù variant here).
  * `contents`: prior messages + the latest user message.
* **Return**: `response.text` ‚Äî the generated answer.
  ‚ö†Ô∏è **Note**: Depending on SDK version, you may need `response.text()` (method) instead of `.text` (property). If you get `undefined`, check SDK docs and update to:

  ```js
  return typeof response.text === 'function' ? response.text() : response.text;
  ```

```js
export default generateResponse
```

* Exports the function to be used in the socket handler.

### What to improve

* **Error handling**:

  ```js
  try { ... } catch (err) { /* log and throw a friendly error */ }
  ```
* **Token budget**: Truncate `chatHistory` (keep last N exchanges) to control latency/cost.
* **Streaming** (optional): If SDK supports, stream tokens for more responsive UX.

---

## 2) `server.js`

### Imports & initialization

```js
import dotenv from 'dotenv'
import app from "./src/app.js";
import { createServer } from "http";
import { Server } from "socket.io";
import generateResponse from './src/service/ai.service.js';

dotenv.config()
```

* Loads `.env`, brings in your **Express app**, Node‚Äôs **HTTP server**, **Socket.IO server**, and your AI service.

```js
const httpServer = createServer(app);
const io = new Server(httpServer, {
    cors : {
        origin : 'http://localhost:5173',
    }
});
```

* **`createServer(app)`**: Wraps Express into an HTTP server (Socket.IO binds to this).
* **`new Server(httpServer, {...})`**: Spins up Socket.IO on the same server.
* **CORS**: Allows browser clients served from **Vite‚Äôs default port 5173** to connect.

### Conversation state

```js
const chatHistory = []
```

* Keeps **all messages from everyone** in memory.
  ‚ö†Ô∏è **Important**: This is **global**. If multiple users connect, they‚Äôll all share one conversation.
  ‚úÖ **Better**: Track per-client history via a `Map`:

  ```js
  const histories = new Map(); // key: socket.id ‚Üí value: array
  ```

### Socket lifecycle

```js
io.on("connection", (socket) => {
   console.log("A user connected"); 

   socket.on("disconnect", (()=> {
     console.log("A user disconnected");
   }))
```

* **`connection`**: fires once per client connection.
* **`disconnect`**: cleanup/logging when a client leaves.
  ‚úÖ If using per-client history, `histories.delete(socket.id)` here.

### Example listener

```js
   socket.on("message", async(data)=> {
     console.log(data);
   })
```

* A generic event handler you can expand later (not used by the UI yet).

### AI request/response loop

```js
   socket.on("ai-message", async(data)=> {
     chatHistory.push({
        role : "user",
        parts : [{text : data}]
     })
    
     const response = await generateResponse(chatHistory)

     chatHistory.push({
        role : "model",
        parts : [{ text : response }]
     })

     socket.emit("ai-message-response", response)
   })
});
```

* **`ai-message`**: Fired by the client when user clicks Send.
* **Append user message** to `chatHistory` (role `"user"`).
* **Call Gemini** with the full history to get a contextual answer.
* **Append model reply** (role `"model"`).
* **`socket.emit("ai-message-response", response)`**: Sends the AI‚Äôs reply **back to the same client** that asked.

### Server listen

```js
httpServer.listen(3000, (()=> {
  console.log("Server is running on port 3000");
}))
```

* Binds the HTTP + Socket.IO server to **port 3000**.

### What to improve

* **Per-socket history**:

  ```js
  io.on('connection', (socket) => {
    const history = [];
    // push into `history` instead of global `chatHistory`
  });
  ```
* **Broadcast vs reply**:

  * `socket.emit(...)` ‚Üí only this client
  * `io.emit(...)` ‚Üí everyone
  * `socket.to(room).emit(...)` ‚Üí others in room
* **Error safety** in the `ai-message` handler (try/catch & send a fallback message).
* **Rate limiting** to prevent abuse.

---

# üíª Frontend

## 3) `src/App.jsx`

### Imports & CSS

```js
import React, { useState, useEffect, useRef } from "react";
import { io } from "socket.io-client";
import "./App.css";
```

* React hooks for state/effects/refs, **Socket.IO client** for real-time connection, and styles.

### State: socket + messages + input

```js
const [socket, setSocket] = useState(null);
const [messages, setMessages] = useState([
  {
    id: Date.now() + Math.random(),
    text: "Hello! How can I assist you today?",
    sender: "bot",
    timestamp: new Date().toISOString(),
  },
]);
const [input, setInput] = useState("");
const messagesEndRef = useRef(null);
```

* **`socket`**: will hold a live socket connection.
* **`messages`**: UI list of conversation items. Each has:

  * `id` (unique), `text` (content), `sender` (`"user"` or `"bot"`), `timestamp`.
* **`input`**: controlled value of the textarea.
* **`messagesEndRef`**: a dummy element to smoothly scroll to latest message.

### Auto-scroll

```js
useEffect(() => {
  messagesEndRef.current?.scrollIntoView({ behavior: "smooth" });
}, [messages]);
```

* Runs after each `messages` update ‚Üí keeps the view on the latest message.

### Send message

```js
const handleSendMessage = () => {
  if (!input.trim()) return;

  const newMessage = {
    id: Date.now(),
    text: input.trim(),
    sender: "user",
    timestamp: new Date().toISOString(),
  };

  setMessages((prev) => [...prev, newMessage]);
  socket.emit("ai-message", input.trim());
  setInput("");
};
```

* Guards against empty messages.
* **Appends user‚Äôs message** to the UI immediately (optimistic UI).
* **Emits** the text to the server on `"ai-message"`.
* **Clears input**.

### Receive AI response

```js
const incomingMessage = (text) => {
  const incomingMsg = {
    id: Date.now() + Math.random(),
    text,
    sender: "bot",
    timestamp: new Date().toISOString(),
  };
  setMessages((prev) => [...prev, incomingMsg]);
};
```

* Builds a **bot message** and appends it to the chat.

### Enter-to-send

```js
const handleKeyPress = (e) => {
  if (e.key === "Enter" && !e.shiftKey) {
    e.preventDefault();
    handleSendMessage();
  }
};
```

* Press **Enter** to send; **Shift+Enter** inserts a newline.

### Socket connection (mount)

```js
useEffect(() => {
  let socketInstance = io("http://localhost:3000");
  setSocket(socketInstance);

  socketInstance.on("ai-message-response", (response) => {
    incomingMessage(response);
  });
}, []);
```

* Connects to the server **once** on mount (empty dependency array).
* Sets up a listener for `"ai-message-response"` to receive AI replies.
* ‚ö†Ô∏è **Cleanup** recommended to avoid leaks when hot-reloading:

  ```js
  useEffect(() => {
    const s = io("http://localhost:3000");
    setSocket(s);
    s.on("ai-message-response", incomingMessage);
    return () => {
      s.off("ai-message-response", incomingMessage);
      s.disconnect();
    };
  }, []);
  ```

### Render UI

* **Header**:

  ```jsx
  <div className="chat-header">Chat Interface</div>
  ```

* **Message list**:

  ```jsx
  <div className="chat-messages">
    {messages.length === 0 && <div className="no-messages">No messages yet. Start chatting!</div>}
    {messages.map((msg) => (
      <div key={msg.id} className={`chat-message ${msg.sender === "user" ? "right" : "left"}`}>
        <div className="message-text">{msg.text}</div>
        <div className="message-time">{/* formatted time */}</div>
      </div>
    ))}
    <div ref={messagesEndRef} />
  </div>
  ```

  * Uses **conditional CSS classes** to align **user** (right) vs **bot** (left).
  * Formats time with `toLocaleTimeString`.

* **Input row**:

  ```jsx
  <div className="chat-input-container">
    <textarea
      rows="1"
      className="chat-input"
      value={input}
      onChange={(e) => setInput(e.target.value)}
      onKeyDown={handleKeyPress}
      placeholder="Type a message..."
    />
    <button onClick={handleSendMessage} disabled={!input.trim()}>
      Send
    </button>
  </div>
  ```

  * Controlled **textarea**.
  * **Send** button disabled when input is empty.

### What to improve

* **Disable Send** if `socket` is not connected:

  ```jsx
  const isReady = !!socket;
  <button disabled={!input.trim() || !isReady}>Send</button>
  ```
* **Persist chat** to `localStorage`:

  ```js
  useEffect(() => {
    const saved = localStorage.getItem("chatMessages");
    if (saved) setMessages(JSON.parse(saved));
  }, []);
  useEffect(() => {
    localStorage.setItem("chatMessages", JSON.stringify(messages));
  }, [messages]);
  ```
* **Handle errors** from server (add an `"ai-error"` listener and show a soft error bubble).
* **Typing indicator**: emit `"typing"` from client; broadcast to room.

---

# üîÑ End-to-End Flow Recap

1. User types ‚Üí clicks **Send**
2. Frontend **optimistically adds** the user message & emits `"ai-message"` with the text
3. Backend **appends user** to `chatHistory` ‚Üí calls **Gemini** ‚Üí gets a reply
4. Backend **appends model** reply ‚Üí **emits `"ai-message-response"`** to that socket
5. Frontend **receives** and **renders** the bot message ‚Üí auto-scrolls to bottom

---

# ‚úÖ Key Architectural Notes

* **Per-user history**: use a `Map<socketId, history[]>` or identify users and store on Redis/DB for scalability.
* **Security**: Never expose **`GEMINI_API_KEY`** on the client. Keep it server-side.
* **CORS**: Must match your dev server origin (`http://localhost:5173` for Vite).
* **Production**: Add logging, retries, error boundaries, and rate limiting.

---