
# ğŸ“˜ Pinecone Vector Service Notes

This file (`vector.service.js`) is your **service layer** for handling memory storage and retrieval with **Pinecone**. It provides two main functions:

1. âœï¸ **`createMemory`** â†’ Store a new memory (message embedding + metadata) in Pinecone.
2. ğŸ” **`queryMemory`** â†’ Retrieve past memories from Pinecone based on similarity search.

---

## ğŸ§¾ Full Code

```js
// Import the Pinecone library
import { Pinecone } from '@pinecone-database/pinecone'

// Initialize a Pinecone client with your API key
const pc = new Pinecone({ apiKey: process.env.PINECONE_APIKEY });

const cohortChatGptIndex = pc.Index('cohort-chat-gpt')

async function createMemory({vectors, messageId, metadata}){
     await cohortChatGptIndex.upsert([{
        id : messageId ,
        values : vectors,
        metadata
     }])
}

async function queryMemory({queryVector, limit = 5 , metadata}) {
    const data = await cohortChatGptIndex.query({
        vector : queryVector,
        topK : limit,
        filter : metadata ? {metadata} : undefined ,
        includeMetadata : true
    })

    return data.matches
}

export  { createMemory, queryMemory }
```

---

## ğŸ—ï¸ Block-by-Block Explanation

### 1ï¸âƒ£ Import & Client Setup

```js
import { Pinecone } from '@pinecone-database/pinecone'

const pc = new Pinecone({ apiKey: process.env.PINECONE_APIKEY });
```

* ğŸ“¦ **Import Pinecone SDK** â†’ lets you interact with Pinecone.
* ğŸ”‘ **API key** â†’ pulled securely from `.env`.
* ğŸ› ï¸ **Client instance (`pc`)** â†’ acts like a connection handle to Pinecone.

Think of this like **connecting to a database** before you can run queries.

---

### 2ï¸âƒ£ Define the Index

```js
const cohortChatGptIndex = pc.Index('cohort-chat-gpt')
```

* This connects you to the **`cohort-chat-gpt` index** in Pinecone.
* ğŸ—‚ï¸ An **index** = a searchable collection of vectors.
* All memory operations (`upsert`, `query`) will run against this index.

---

### 3ï¸âƒ£ `createMemory` Function âœï¸

```js
async function createMemory({vectors, messageId, metadata}){
     await cohortChatGptIndex.upsert([{
        id : messageId ,
        values : vectors,
        metadata
     }])
}
```

#### ğŸ”‘ What it does:

* **Upserts** (insert/update) a new memory into Pinecone.
* Accepts:

  * `vectors` â†’ the embedding (array of floats, e.g. `[0.12, 0.34, ...]`)
  * `messageId` â†’ unique identifier for the memory (so it can be updated later)
  * `metadata` â†’ JSON with extra context (`chatId`, `userId`, `text`, etc.)

#### Example:

```js
await createMemory({
  vectors: [0.1, 0.2, 0.3, ...],
  messageId: "msg-101",
  metadata: { chat: "chat-1", user: "u123", text: "Hey there!" }
})
```

ğŸ‘‰ Pinecone now stores this embedding and links it to your metadata.
ğŸ‘‰ If `msg-101` already exists, Pinecone **updates** it.

---

### 4ï¸âƒ£ `queryMemory` Function ğŸ”

```js
async function queryMemory({queryVector, limit = 5 , metadata}) {
    const data = await cohortChatGptIndex.query({
        vector : queryVector,
        topK : limit,
        filter : metadata ? {metadata} : undefined ,
        includeMetadata : true
    })

    return data.matches
}
```

#### ğŸ”‘ What it does:

* Performs a **similarity search** in Pinecone.
* Accepts:

  * `queryVector` â†’ the embedding of the search query.
  * `limit` â†’ number of closest matches to return (`topK`).
  * `metadata` â†’ optional filter (e.g., search only inside a certain chat).

#### Key Options:

* `vector: queryVector` â†’ the embedding youâ€™re comparing against.
* `topK: limit` â†’ how many matches to return.
* `filter` â†’ restrict results (only from certain `chatId` or `user`).
* `includeMetadata: true` â†’ ensures you also get stored metadata (`text`, `chat`, `user`) in the results.

#### Example:

```js
const results = await queryMemory({
  queryVector: [0.1, 0.2, 0.3, ...],
  limit: 3,
  metadata: { chat: { $eq: "chat-1" } }
})

console.log(results)
```

ğŸ‘‰ Returns up to 3 closest memories **from chat-1**, including their metadata.

---

### 5ï¸âƒ£ Exporting Functions ğŸšª

```js
export { createMemory, queryMemory }
```

* Makes both functions reusable in other files (like your `socket.server.js`).
* Typical usage:

```js
import { createMemory, queryMemory } from './vector.service.js'
```

---

## ğŸ§  How It Fits in Your App

* ğŸ“¨ When a **user sends a message** â†’ you create an embedding â†’ call `createMemory()` â†’ store it in Pinecone.
* ğŸ” When you need **context for a new query** â†’ you embed the query â†’ call `queryMemory()` â†’ fetch past relevant messages.

This is the foundation of a **memory system** for your chatbot (like ChatGPT with memory).

---

## âœ¨ Analogy

Think of Pinecone as a **giant smart notebook**:

* âœï¸ `createMemory` = writing a note into the notebook (with labels).
* ğŸ” `queryMemory` = flipping through the notebook to find notes most related to your current question.

---

âœ… With this service, your chatbot can **remember past chats**, **search by meaning**, and **provide context-aware responses**.

---