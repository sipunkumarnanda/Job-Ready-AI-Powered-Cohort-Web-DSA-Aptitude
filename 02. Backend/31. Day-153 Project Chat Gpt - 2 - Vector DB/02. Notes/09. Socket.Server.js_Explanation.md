
# ⚡ `socket.server.js` — Notes

---

## 📜 Full Code

```js
import { Server } from "socket.io";
import cookie from "cookie";
import jwt from "jsonwebtoken";
import userModel from "../models/user.model.js";
import {generateResponse, generateVectors} from "../services/ai.service.js";
import messageModel from "../models/message.model.js";
import { createMemory, queryMemory } from "../services/vector.service.js";

function initSocketServer(httpServer) {
  const io = new Server(httpServer, {});

  io.use(async (socket, next) => {
    const cookies = cookie.parse(socket.handshake.headers?.cookie || "");

    if (!cookies.token) {
      next(new Error("Authentication error : No token provided"));
    }

    try {
      const decoded = jwt.verify(cookies.token, process.env.JWT_SECRETE);

      const user = await userModel.findById(decoded.id);

      socket.user = user;
      next();
    } catch (error) {
      next(new Error("Authentication error : Invalid token"));
    }
  });

  io.on("connection", (socket) => {
    socket.on("ai-message", async (messagePayload) => {
      try {

        if (!messagePayload?.chatId || !messagePayload?.content) {
          socket.emit("ai-response", {
            error: "chatId and content are required",
          });
          return;   // stop execution here
        }

        // write data to mongoDB
        const message = await messageModel.create({
          chatId: messagePayload.chatId,
          userId: socket.user._id,
          content: messagePayload.content,
          role: "user",
        });

        // Generate vectors 
        const vectors = await generateVectors(messagePayload.content)

        // old messages from pinecone / vectors 
        const memory = await queryMemory({
          queryVector : vectors,
          limit : 3,
          metadata : {}
        })

        console.log(" Memory : ",memory);

        // save on pinecone
        await createMemory({
          vectors : vectors,
          messageId : message._id,
          metadata : {
            chat : messagePayload.chatId,
            user : socket.user._id,
            text : messagePayload.content
          },
        })

        // last 20 messages (short-term memory)
        const chatHistory = (
          await messageModel.find({
              chatId: messagePayload.chatId,
            }).sort({ createdAt: -1 }).limit(20).lean()).reverse();

        // feed data to ai
        const response = await generateResponse(
          chatHistory.map((item) => {
            return {
              role: item.role,
              parts: [{ text: item.content }],
            };
          })
        );

        // save response from ai in DB 
        const responseMessage = await messageModel.create({
          chatId: messagePayload.chatId,
          userId: socket.user._id,
          content: response,
          role: "model",
        });

        // Generate vectors for AI response 
        const responseVectors = await generateVectors(response)

        // save on pinecone
        await createMemory({
          vectors : responseVectors,
          messageId : responseMessage._id,
          metadata : {
            chat : messagePayload.chatId,
            user : socket.user._id,
            text : response
          },
        })

        // emit ai response back to client
        socket.emit("ai-response", {
          chat: messagePayload.chat,
          content: response,
        });

      } catch (error) {
        socket.emit("ai-response", {
          error: "Something went wrong on the server",
        });
      }
    });

    socket.on("disconnect", () => {
      console.log("A user is disconnected");
    });
  });
}

export default initSocketServer;
```

---

## 📝 Explanation (Block by Block)

---

### 1️⃣ Import Dependencies

```js
import { Server } from "socket.io";
import cookie from "cookie";
import jwt from "jsonwebtoken";
import userModel from "../models/user.model.js";
import {generateResponse, generateVectors} from "../services/ai.service.js";
import messageModel from "../models/message.model.js";
import { createMemory, queryMemory } from "../services/vector.service.js";
```

* **Socket.IO** → Real-time communication between server & client.
* **cookie** → Extract JWT token from browser cookies.
* **jsonwebtoken** → Verify user identity.
* **userModel & messageModel** → MongoDB models for Users & Messages.
* **Gemini service (`generateResponse`, `generateVectors`)** → For AI text + embeddings.
* **Pinecone service (`createMemory`, `queryMemory`)** → For storing & retrieving long-term memory.

---

### 2️⃣ Init Socket.IO Server

```js
function initSocketServer(httpServer) {
  const io = new Server(httpServer, {});
```

* Wraps your HTTP server with **real-time WebSocket support**.
* All chat connections will go through `io`.

---

### 3️⃣ Middleware — Authenticate User

```js
io.use(async (socket, next) => {
  const cookies = cookie.parse(socket.handshake.headers?.cookie || "");

  if (!cookies.token) {
    next(new Error("Authentication error : No token provided"));
  }

  try {
    const decoded = jwt.verify(cookies.token, process.env.JWT_SECRETE);
    const user = await userModel.findById(decoded.id);

    socket.user = user; // attach user to socket
    next();
  } catch (error) {
    next(new Error("Authentication error : Invalid token"));
  }
});
```

* Ensures **only logged-in users** can connect.
* Extracts `token` from cookies → verifies with `JWT`.
* Fetches user from DB → attaches it to `socket.user`.
* If token is missing/invalid → blocks the connection.

⚡ Security layer for real-time chats.

---

### 4️⃣ On New Connection

```js
io.on("connection", (socket) => {
```

* Runs whenever a **user successfully connects**.
* Each `socket` = one user’s live connection.

---

### 5️⃣ Handle `"ai-message"` Event

```js
socket.on("ai-message", async (messagePayload) => {
```

This is the **main AI chat pipeline**:

#### a) ✅ Validate Input

```js
if (!messagePayload?.chatId || !messagePayload?.content) {
  socket.emit("ai-response", { error: "chatId and content are required" });
  return;
}
```

* Ensures message has both `chatId` and `content`.

---

#### b) 🗄 Save User Message in DB

```js
const message = await messageModel.create({
  chatId: messagePayload.chatId,
  userId: socket.user._id,
  content: messagePayload.content,
  role: "user",
});
```

* Stores user’s message in MongoDB.
* Tagged with `role: "user"`.

---

#### c) 📊 Convert User Message to Vectors

```js
const vectors = await generateVectors(messagePayload.content)
```

* Embeds user message into a **768-dim vector** via Gemini.

---

#### d) 🔎 Retrieve Related Memories from Pinecone

```js
const memory = await queryMemory({
  queryVector : vectors,
  limit : 3,
  metadata : {}
})
```

* Finds top **3 most similar past messages**.
* Acts like **long-term memory recall**.

---

#### e) 💾 Save User Message in Pinecone

```js
await createMemory({
  vectors : vectors,
  messageId : message._id,
  metadata : {
    chat : messagePayload.chatId,
    user : socket.user._id,
    text : messagePayload.content
  },
})
```

* Stores embedding + metadata in Pinecone for future queries.

---

#### f) 🧠 Prepare Chat History (Short-Term Memory)

```js
const chatHistory = (
  await messageModel.find({ chatId: messagePayload.chatId })
    .sort({ createdAt: -1 }).limit(20).lean()
).reverse();
```

* Gets last **20 messages** for short-term context.
* Reversed so the **oldest comes first**.

---

#### g) 🤖 Generate AI Response

```js
const response = await generateResponse(
  chatHistory.map((item) => ({
    role: item.role,
    parts: [{ text: item.content }],
  }))
);
```

* Sends chat history → Gemini.
* Returns an **AI-generated response**.

---

#### h) 🗄 Save AI Response in DB

```js
const responseMessage = await messageModel.create({
  chatId: messagePayload.chatId,
  userId: socket.user._id,
  content: response,
  role: "model",
});
```

* Stores AI’s response in MongoDB.
* Tagged with `role: "model"`.

---

#### i) 📊 Generate & Save Response Vectors

```js
const responseVectors = await generateVectors(response)
await createMemory({
  vectors : responseVectors,
  messageId : responseMessage._id,
  metadata : {
    chat : messagePayload.chatId,
    user : socket.user._id,
    text : response
  },
})
```

* Embeds AI’s response → saves in Pinecone.
* Ensures **both user + AI messages** go into memory.

---

#### j) 📤 Emit Response Back to Client

```js
socket.emit("ai-response", {
  chat: messagePayload.chat,
  content: response,
});
```

* Sends AI’s reply back to the user in real time.

---

### 6️⃣ Handle Disconnect

```js
socket.on("disconnect", () => {
  console.log("A user is disconnected");
});
```

* Logs when a user leaves the chat.

---

## 🎯 Summary Flow

1. User sends message → validated.
2. Message saved in MongoDB.
3. Converted into vector → searched in Pinecone for related context.
4. Saved into Pinecone for future use.
5. Retrieve last 20 messages (short-term memory).
6. Send chat history to Gemini → AI generates response.
7. Save AI response in MongoDB + Pinecone.
8. Emit AI response back to client.

---

## ✨ Analogy

Think of this like a **human brain**:

* **MongoDB** → like a diary (stores all conversations).
* **Pinecone** → like long-term memory recall (search old related memories).
* **Chat history (20 msgs)** → like short-term memory (what you just talked about).
* **Gemini** → the brain that speaks back.
* **Socket.IO** → the mouth/ears that let you talk in real-time.

---