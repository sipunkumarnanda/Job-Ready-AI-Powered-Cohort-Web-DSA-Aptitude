
# 🧠 Gemini API Integration Guide

## 1. 🎟️ Getting Your API Key

* Sign in to **Google AI Studio** and navigate to the **Gemini API → API key** section. You can create one for free ([Google AI for Developers][1]).
* For local development, set it as an environment variable:

  * **Linux/macOS (bash/zsh)**: `export GEMINI_API_KEY=YOUR_KEY`
  * **Windows**: Set via System → Environment Variables ([Google AI for Developers][1]).
* Alternatively, you can pass the API key explicitly in code—especially useful for REST or web prototyping ([Google AI for Developers][1]).

---

## 2. 📦 Installing the SDK

Use the **Google Gen AI SDK** named `@google/genai` to call Gemini:

```bash
npm install @google/genai
```

*(for Node.js/TypeScript)* ([Google AI for Developers][2])

---

## 3. 🚀 Writing Your First Call in JavaScript

```js
import { GoogleGenAI } from "@google/genai";

const ai = new GoogleGenAI({});
async function main() {
  const response = await ai.models.generateContent({
    model: "gemini-2.5-flash",
    contents: "Explain how AI works in a few words",
  });
  console.log(response.text);
}
main();
```

* If `GEMINI_API_KEY` environment variable is set, the SDK auto-picks it up.
* Otherwise, you can explicitly specify:
  `new GoogleGenAI({ apiKey: "YOUR_API_KEY" })` ([Google AI for Developers][2])

---

## 4. 🔥 Model Versions

* **Gemini 2.5 Flash**: Fast, cost-efficient, ideal for general text generation tasks.
* **Gemini 2.5 Pro**: More capable; supports reasoning and “Deep Think” mode.
* **Streaming & Live API**: Supports low-latency audio/video interactions. ([en.wikipedia.org][3], [Google for Developers][4])

---

## 5. 🧪 Advanced Use Cases & Multimodality

* Gemini API supports **multimodal inputs** (text + images + audio + video).
* Use the `contents` array to include parts like `{ text }`, `inlineData`, or `fileData` (for images/files) ([Google Cloud][5]).
* Example: image analysis or describing visual content.

---

## 6. 📡 Using the API via REST (No SDK)

```bash
curl "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=$GEMINI_API_KEY" \
  -X POST -H "Content-Type: application/json" \
  -d '{
    "contents": [{"parts":[{"text":"Describe AI in simple terms."}]}]
  }'
```

* Requires `x-goog-api-key` header if not using `?key=` parameter.
* Must follow the JSON schema: `contents` array, with nested `parts` for text/inlineData/fileData ([Google AI for Developers][6]).

---

## 7. ✅ Best Practices & Security

* **Never expose your API key in client-side code** for production; use server-side calls or Firebase AI Logic instead ([Google for Developers][4]).
* **Use API restrictions** in Google Cloud console to limit usage.
* For client-side interaction like Live API, use **ephemeral tokens** instead of raw API keys ([Google AI for Developers][1]).

---

## 8. 🏗️ Scaling to Production

* For prototypes, direct SDK calls are fine.
* For production-level apps, migrate to **Firebase AI Logic** or **Vertex AI**:

  * Provides secure remote execution
  * Media upload support
  * Scalable infrastructure and enterprise-grade features ([Google for Developers][4]).

---

## 9. 🧾 Summary Table

| Step               | Action                                          |
| ------------------ | ----------------------------------------------- |
| Get API Key        | Google AI Studio → Gemini API → Create key      |
| Set Key            | Via environment or explicit in code             |
| Install SDK        | `npm install @google/genai`                     |
| Example API Call   | Use `generateContent()` with `contents`         |
| Multimodal Prompts | Include text/image/video as inline or file data |
| REST Option        | `curl` with proper JSON schema                  |
| Security           | Protect or restrict your API key                |
| Production         | Use Firebase AI Logic or Vertex AI              |

---

## 10. 🧱 Example Full Server-Side Integration (Node.js/Express)

```js
import express from 'express';
import { GoogleGenAI } from '@google/genai';
const ai = new GoogleGenAI({});

const app = express();
app.use(express.json());

app.post('/generate', async (req, res) => {
  const prompt = req.body.prompt;
  if (!prompt) return res.status(400).json({ error: 'Prompt required' });

  try {
    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash',
      contents: [{ parts: [{ text: prompt }] }],
    });
    res.json({ text: response.text });
  } catch (err) {
    console.error(err);
    res.status(500).json({ error: 'API call failed' });
  }
});

app.listen(3000, () => console.log('Server listening on :3000'));
```

---

[1]: https://ai.google.dev/gemini-api/docs/api-key?utm_source=chatgpt.com "Using Gemini API keys | Google AI for Developers"
[2]: https://ai.google.dev/gemini-api/docs/quickstart?utm_source=chatgpt.com "Gemini API quickstart | Google AI for Developers"
[3]: https://en.wikipedia.org/wiki/Gemini_%28language_model%29?utm_source=chatgpt.com "Gemini (language model)"
[4]: https://developers.google.com/learn/pathways/solution-ai-gemini-getting-started-web?utm_source=chatgpt.com "Getting started with the Gemini API and Web apps"
[5]: https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference?utm_source=chatgpt.com "Generate content with the Gemini API in Vertex AI"
[6]: https://ai.google.dev/gemini-api/docs?utm_source=chatgpt.com "Gemini API | Google AI for Developers"
